{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1ee0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "idir = \"/Users/BlacKay/Documents/Projects/Images/test/bust/\"\n",
    "idir = \"/Users/BlacKay/Documents/Projects/Images/test/templeRing/\"\n",
    "import cv2\n",
    "\n",
    "nimages = 10\n",
    "images = []\n",
    "\n",
    "for i in range(nimages):\n",
    "    iname = f\"{idir}/{i:08d}.jpg\"\n",
    "    img = cv2.imread(iname)\n",
    "    images.append(img)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d0f303",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "# Initialize SIFT (parameters roughly matching your C++ example)\n",
    "# Note: Not all SiftParams map directly to cv2.SIFT_create(), so we use similar ones.\n",
    "sift = cv2.SIFT_create(\n",
    "    nfeatures=0,           # similar to octave settings\n",
    "    nOctaveLayers=3,       # 2nd param (matches your 3)\n",
    "    contrastThreshold=0.04,\n",
    "    edgeThreshold=10,\n",
    "    sigma=1.6\n",
    ")\n",
    "\n",
    "keys = [[] for _ in range(nimages)]\n",
    "descs = [[] for _ in range(nimages)]\n",
    "\n",
    "for i in range(nimages):\n",
    "    gray = cv2.cvtColor(images[i], cv2.COLOR_BGR2GRAY)\n",
    "    kpts, descriptors = sift.detectAndCompute(gray, None)\n",
    "    keys[i] = kpts\n",
    "    descs[i] = descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493c2242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "\n",
    "class DMatch:\n",
    "    def __init__(self, ikey1=None, ikey2=None, pt1=None, pt2=None, dist=None):\n",
    "        # Handle different constructor variants\n",
    "        if pt1 is not None and pt2 is not None:\n",
    "            self.ind_key_ = (ikey1, ikey2)\n",
    "            self.point_ = (np.array(pt1, dtype=float), np.array(pt2, dtype=float))\n",
    "            self.dist_ = float(dist)\n",
    "        elif ikey1 is not None and ikey2 is not None and dist is not None:\n",
    "            self.ind_key_ = (ikey1, ikey2)\n",
    "            self.point_ = (None, None)\n",
    "            self.dist_ = float(dist)\n",
    "        elif ikey1 is None and ikey2 is None and dist is None:\n",
    "            self.ind_key_ = (None, None)\n",
    "            self.point_ = (None, None)\n",
    "            self.dist_ = None\n",
    "        elif isinstance(ikey1, DMatch):\n",
    "            # Copy constructor\n",
    "            match = ikey1\n",
    "            self.ind_key_ = match.ind_key_\n",
    "            self.point_ = match.point_\n",
    "            self.dist_ = match.dist_\n",
    "        else:\n",
    "            raise ValueError(\"Invalid constructor arguments for DMatch\")\n",
    "\n",
    "    def dist(self) -> float:\n",
    "        \"\"\"Return the match distance.\"\"\"\n",
    "        return self.dist_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7a9087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "\n",
    "class Pair:\n",
    "    def __init__(self, cam1=None, cam2=None, matches=None):\n",
    "        \"\"\"\n",
    "        Python equivalent of the C++ Pair constructors.\n",
    "        Supports:\n",
    "          - Pair()\n",
    "          - Pair(cam1, cam2)\n",
    "          - Pair(cam1, cam2, matches)\n",
    "        \"\"\"\n",
    "        self.cams_ = []\n",
    "        self.matches_ = []\n",
    "        self.F_ = np.eye(3, dtype=float)\n",
    "        self.E_ = np.eye(3, dtype=float)\n",
    "        self.intrinsics_mat_ = []\n",
    "        self.extrinsics_mat_ = []\n",
    "\n",
    "        if cam1 is not None and cam2 is not None:\n",
    "            self.init(cam1, cam2)\n",
    "            if matches is not None:\n",
    "                # Matches can be list of (Vec2f, Vec2f) or list of DMatch\n",
    "                if all(isinstance(m, DMatch) for m in matches):\n",
    "                    self.matches_ = matches\n",
    "                elif all(isinstance(m, tuple) and len(m) == 2 for m in matches):\n",
    "                    # Convert raw (pt1, pt2) to DMatch objects with dummy distance\n",
    "                    self.matches_ = [DMatch(i, i, m[0], m[1], 0.0) for i, m in enumerate(matches)]\n",
    "                else:\n",
    "                    raise ValueError(\"matches must be list of DMatch or list of (Vec2f, Vec2f) pairs\")\n",
    "\n",
    "    def init(self, ind_cam1: int, ind_cam2: int):\n",
    "        \"\"\"Initialize the pair with two camera indices.\"\"\"\n",
    "        self.cams_ = [ind_cam1, ind_cam2]\n",
    "\n",
    "    def update_matches(self, vote_inlier: np.ndarray):\n",
    "        \"\"\"Update matches using an inlier mask (1 for inlier, 0 for outlier).\"\"\"\n",
    "        self.matches_ = [m for m, v in zip(self.matches_, vote_inlier) if v]\n",
    "\n",
    "    def update_intrinsics(self, f: float, w: int, h: int):\n",
    "        \"\"\"Compute intrinsics matrix for both cameras based on focal length and image size.\"\"\"\n",
    "        K = np.array([[f, 0, w / 2],\n",
    "                      [0, f, h / 2],\n",
    "                      [0, 0, 1]], dtype=float)\n",
    "        self.intrinsics_mat_ = [K.copy(), K.copy()]\n",
    "\n",
    "    def __lt__(self, rhs: 'Pair') -> bool:\n",
    "        \"\"\"Implements operator< for sorting.\"\"\"\n",
    "        return tuple(self.cams_) < tuple(rhs.cams_)\n",
    "\n",
    "    def baseline_angle(self) -> float:\n",
    "        \"\"\"Placeholder for baseline angle computation.\"\"\"\n",
    "        # You can compute this later from extrinsics if available\n",
    "        return 0.0  # Placeholder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376e858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "pairs = []\n",
    "odir = \"/path/to/output/\"  # ← set this properly\n",
    "\n",
    "# Equivalent of: Matcher_Param(0.6*0.6, 50)\n",
    "ratio_thresh = 0.6 * 0.6\n",
    "max_matches = 50\n",
    "\n",
    "# FLANN parameters for SIFT descriptors (float32)\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "flann_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = dict(checks=50)\n",
    "matcher = cv2.FlannBasedMatcher(flann_params, search_params)\n",
    "\n",
    "matches_pairwise = [[] for _ in range(nimages - 1)]\n",
    "\n",
    "for i in range(nimages - 1):\n",
    "    matches_pairwise[i] = [[] for _ in range(nimages - (i + 1))]\n",
    "    for j in range(i + 1, nimages):\n",
    "        # Perform KNN matching (k=2) for ratio test\n",
    "        knn_matches = matcher.knnMatch(descs[i], descs[j], k=2)\n",
    "\n",
    "        # Lowe’s ratio test\n",
    "        good_matches = []\n",
    "        for m, n in knn_matches:\n",
    "            if m.distance < ratio_thresh * n.distance:\n",
    "                good_matches.append(DMatch(m.queryIdx, m.trainIdx, m.distance))\n",
    "\n",
    "        # Keep only top matches if needed\n",
    "        good_matches = sorted(good_matches, key=lambda x: x.dist_)[:max_matches]\n",
    "\n",
    "        matches_pairwise[i][j - (i + 1)] = good_matches\n",
    "\n",
    "        # Store the pair\n",
    "        pairs.append(Pair(i, j, good_matches))\n",
    "\n",
    "        # Write matches to text file\n",
    "        fname = os.path.join(odir, f\"matching{i+1}_{j+1}.txt\")\n",
    "        with open(fname, \"w\") as f:\n",
    "            for m in good_matches:\n",
    "                f.write(f\"{m.ind_key_[0]} {m.ind_key_[1]} {m.dist_}\\n\")\n",
    "\n",
    "        # (Optional) draw matches\n",
    "        if False:\n",
    "            img_matches = cv2.drawMatches(\n",
    "                images[i], keys[i],\n",
    "                images[j], keys[j],\n",
    "                [cv2.DMatch(m.ind_key_[0], m.ind_key_[1], m.dist_) for m in good_matches],\n",
    "                None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    "            )\n",
    "            out_path = os.path.join(odir, f\"matching{i+1}_{j+1}.jpg\")\n",
    "            cv2.imwrite(out_path, img_matches)\n",
    "\n",
    "        print(f\"Image ({i+1}, {j+1}): matches number: {len(good_matches)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9310d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "thresh_inlier_ratio = 0.3  # example threshold, adjust as in your C++ code\n",
    "\n",
    "for pair in pairs:\n",
    "    nmatches = len(pair.matches_)\n",
    "    ind1, ind2 = pair.cams_\n",
    "\n",
    "    print(\"*******************************\")\n",
    "    print(f\" 2-View SfM of image {ind1+1} and {ind2+1}\")\n",
    "    print(\"*******************************\")\n",
    "\n",
    "    # --- Build matched points from DMatch objects ---\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "    for m in pair.matches_:\n",
    "        # Retrieve keypoint coordinates from the original keypoint lists\n",
    "        pt1 = keys[ind1][m.ind_key_[0]].pt\n",
    "        pt2 = keys[ind2][m.ind_key_[1]].pt\n",
    "        pts1.append(pt1)\n",
    "        pts2.append(pt2)\n",
    "\n",
    "    pts1 = np.array(pts1, dtype=np.float32)\n",
    "    pts2 = np.array(pts2, dtype=np.float32)\n",
    "\n",
    "    if len(pts1) < 8:\n",
    "        print(\"Not enough matches for fundamental matrix estimation, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # --- Estimate Fundamental Matrix with RANSAC ---\n",
    "    F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC, 1e-8, 0.99)\n",
    "\n",
    "    if F is None or mask is None:\n",
    "        print(\"Fundamental matrix estimation failed.\")\n",
    "        continue\n",
    "\n",
    "    inlier_ratio = float(np.sum(mask)) / len(mask)\n",
    "    print(f\"Ratio of matching inliers: {inlier_ratio:.3f}\")\n",
    "\n",
    "    if inlier_ratio < thresh_inlier_ratio:\n",
    "        continue\n",
    "\n",
    "    # Store F in the Pair object (ensure it’s 3x3)\n",
    "    pair.F_ = F.reshape(3, 3)\n",
    "\n",
    "    # Optional: store inlier matches\n",
    "    inlier_mask = mask.ravel().astype(bool)\n",
    "    pair.update_matches(inlier_mask)\n",
    "\n",
    "    # (other code continues here, e.g. Essential matrix estimation, triangulation, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaeb60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "f = 1520.4\n",
    "w, h = int(302.32 * 2), int(246.87 * 2)\n",
    "\n",
    "# Update intrinsics (fills pair.intrinsics_mat_ with two K matrices)\n",
    "pair.update_intrinsics(f, w, h)\n",
    "\n",
    "# Compute Essential matrix: E = K2ᵀ * F * K1\n",
    "K1 = pair.intrinsics_mat_[0]\n",
    "K2 = pair.intrinsics_mat_[1]\n",
    "pair.E_ = K2.T @ pair.F_ @ K1\n",
    "\n",
    "# ---- Decompose Essential Matrix to get R and t ----\n",
    "def Rt_from_E(pair):\n",
    "    E = pair.E_\n",
    "\n",
    "    # Recover pose from essential matrix\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "    for m in pair.matches_:\n",
    "        pt1 = keys[pair.cams_[0]][m.ind_key_[0]].pt\n",
    "        pt2 = keys[pair.cams_[1]][m.ind_key_[1]].pt\n",
    "        pts1.append(pt1)\n",
    "        pts2.append(pt2)\n",
    "\n",
    "    pts1 = np.array(pts1, dtype=np.float32)\n",
    "    pts2 = np.array(pts2, dtype=np.float32)\n",
    "\n",
    "    # Use OpenCV's recoverPose\n",
    "    _, R, t, mask = cv2.recoverPose(E, pts1, pts2, K1)\n",
    "\n",
    "    # Store extrinsics for both cameras (assuming first camera is at origin)\n",
    "    M1 = np.hstack((np.eye(3), np.zeros((3, 1))))  # [R|t] = [I|0]\n",
    "    M2 = np.hstack((R, t))\n",
    "    pair.extrinsics_mat_ = [M1, M2]\n",
    "\n",
    "    print(\"Recovered rotation:\\n\", R)\n",
    "    print(\"Recovered translation:\\n\", t)\n",
    "\n",
    "# Call it\n",
    "Rt_from_E(pair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10b0e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self, pair=None):\n",
    "        \"\"\"\n",
    "        Equivalent to:\n",
    "          Graph()          → empty graph\n",
    "          Graph(const Pair&) → initialize from a Pair\n",
    "        \"\"\"\n",
    "        self.ncams_ = 0\n",
    "        self.ind_cam_ = []\n",
    "        self.intrinsics_mat_ = []\n",
    "        self.extrinsics_mat_ = []\n",
    "        self.tracks_ = []\n",
    "        self.structure_points_ = []\n",
    "\n",
    "        if pair is not None:\n",
    "            self.init(pair)\n",
    "\n",
    "    def init(self, pair):\n",
    "        \"\"\"Initialize graph from a Pair object.\"\"\"\n",
    "        self.ncams_ = len(pair.cams_)\n",
    "        self.ind_cam_ = pair.cams_.copy()\n",
    "        self.intrinsics_mat_ = pair.intrinsics_mat_.copy()\n",
    "        self.extrinsics_mat_ = pair.extrinsics_mat_.copy()\n",
    "\n",
    "    def index(self, icam: int) -> int:\n",
    "        \"\"\"\n",
    "        Return the index of a camera id in ind_cam_.\n",
    "        Returns -1 if not found.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.ind_cam_.index(icam)\n",
    "        except ValueError:\n",
    "            return -1\n",
    "\n",
    "    def size(self) -> int:\n",
    "        \"\"\"Return the number of cameras.\"\"\"\n",
    "        return self.ncams_\n",
    "\n",
    "    @staticmethod\n",
    "    def intersect(tracks1: List[\"Track\"], tracks2: List[\"Track\"]) -> List[int]:\n",
    "        \"\"\"\n",
    "        Compute intersection between two track sets.\n",
    "        (Assuming each Track has an attribute 'id' or similar identifier)\n",
    "        \"\"\"\n",
    "        ids1 = {t.id for t in tracks1}\n",
    "        ids2 = {t.id for t in tracks2}\n",
    "        return list(ids1 & ids2)\n",
    "    \n",
    "    def add_track(self, track):\n",
    "        self.tracks_.append(track)\n",
    "\n",
    "    def add_struct_pt(self, struct_pt):\n",
    "        self.structure_points_.append(struct_pt)\n",
    "\n",
    "    @staticmethod\n",
    "    def merge_tracks(track1, track2, feats_common):\n",
    "        # merge observations from track2 into track1\n",
    "        for (cam_id, _) in feats_common:\n",
    "            if cam_id not in [obs.cam_id for obs in track1.observations]:\n",
    "                track1.observations.append(next(o for o in track2.observations if o.cam_id == cam_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452f5a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def triangulate_nonlinear(graph):\n",
    "    \"\"\"\n",
    "    Triangulate 3D points between the first two cameras in the graph.\n",
    "    Stores them into graph.structure_points_.\n",
    "    \"\"\"\n",
    "    if len(graph.extrinsics_mat_) < 2:\n",
    "        print(\"Need at least two camera poses to triangulate.\")\n",
    "        return\n",
    "\n",
    "    P1 = graph.intrinsics_mat_[0] @ graph.extrinsics_mat_[0]\n",
    "    P2 = graph.intrinsics_mat_[1] @ graph.extrinsics_mat_[1]\n",
    "\n",
    "    # Collect corresponding points from tracks (assuming you have them)\n",
    "    pts1, pts2 = [], []\n",
    "    for track in graph.tracks_:\n",
    "        # Assuming each Track has image points (pt1, pt2)\n",
    "        pts1.append(track.pt1)\n",
    "        pts2.append(track.pt2)\n",
    "\n",
    "    pts1 = np.array(pts1, dtype=np.float32)\n",
    "    pts2 = np.array(pts2, dtype=np.float32)\n",
    "\n",
    "    if len(pts1) == 0:\n",
    "        print(\"No tracks to triangulate.\")\n",
    "        return\n",
    "\n",
    "    # Linear triangulation\n",
    "    points4D_h = cv2.triangulatePoints(P1, P2, pts1.T, pts2.T)\n",
    "\n",
    "    # Convert from homogeneous to 3D\n",
    "    points3D = (points4D_h[:3] / points4D_h[3]).T\n",
    "\n",
    "    # Store the structure points in the graph\n",
    "    graph.structure_points_ = points3D\n",
    "\n",
    "\n",
    "def reprojection_error(graph):\n",
    "    \"\"\"\n",
    "    Compute average reprojection error for all 3D points in the graph.\n",
    "    \"\"\"\n",
    "    if not hasattr(graph, \"structure_points_\") or len(graph.structure_points_) == 0:\n",
    "        return np.inf\n",
    "\n",
    "    total_error = 0.0\n",
    "    total_points = 0\n",
    "\n",
    "    for cam_idx in range(graph.ncams_):\n",
    "        P = graph.intrinsics_mat_[cam_idx] @ graph.extrinsics_mat_[cam_idx]\n",
    "        pts3D_h = np.hstack((graph.structure_points_, np.ones((len(graph.structure_points_), 1))))\n",
    "        proj = (P @ pts3D_h.T).T\n",
    "        proj = proj[:, :2] / proj[:, 2, np.newaxis]\n",
    "\n",
    "        # Assuming each track stores the corresponding observed 2D points\n",
    "        observed = np.array([t.pt1 if cam_idx == 0 else t.pt2 for t in graph.tracks_])\n",
    "        err = np.linalg.norm(proj - observed, axis=1)\n",
    "\n",
    "        total_error += np.sum(err)\n",
    "        total_points += len(err)\n",
    "\n",
    "    return total_error / max(total_points, 1)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "triangulate_nonlinear(graph[i])\n",
    "error = reprojection_error(graph[i])\n",
    "print(f\"Reprojection error (before bundle adjustment): {error:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93843c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "def Open3DCVBundleAdjustment(graph, mode=\"BUNDLE_NO_INTRINSICS\"):\n",
    "    \"\"\"\n",
    "    Simplified Python equivalent of Open3DCVBundleAdjustment.\n",
    "    Supports:\n",
    "      - \"BUNDLE_NO_INTRINSICS\": only refines poses and 3D points\n",
    "      - \"BUNDLE_FOCAL_LENGTH\": refines focal length too\n",
    "      - \"BUNDLE_INTRINSICS\": refines full intrinsics\n",
    "    \"\"\"\n",
    "\n",
    "    # Flatten camera parameters (R,t) for optimization\n",
    "    camera_params = []\n",
    "    for P in graph.extrinsics_mat_:\n",
    "        R = P[:, :3]\n",
    "        t = P[:, 3]\n",
    "        rvec, _ = cv2.Rodrigues(R)\n",
    "        camera_params.append(np.hstack((rvec.flatten(), t.flatten())))\n",
    "    camera_params = np.concatenate(camera_params)\n",
    "\n",
    "    points_3d = graph.structure_points_.copy()\n",
    "\n",
    "    # Bundle intrinsics\n",
    "    f = graph.intrinsics_mat_[0][0, 0]\n",
    "    cx, cy = graph.intrinsics_mat_[0][0, 2], graph.intrinsics_mat_[0][1, 2]\n",
    "\n",
    "    # Prepare observations\n",
    "    obs = []\n",
    "    for cam_idx in range(graph.ncams_):\n",
    "        obs.append(np.array([t.pt1 if cam_idx == 0 else t.pt2 for t in graph.tracks_]))\n",
    "    obs = np.stack(obs, axis=0)  # shape (n_cams, n_points, 2)\n",
    "\n",
    "    def project(points, rvec, tvec, f, cx, cy):\n",
    "        pts, _ = cv2.projectPoints(points, rvec, tvec, np.array([[f, 0, cx], [0, f, cy], [0, 0, 1]]), None)\n",
    "        return pts.reshape(-1, 2)\n",
    "\n",
    "    def residual(params):\n",
    "        # Unpack parameters\n",
    "        ptr = 0\n",
    "        res = []\n",
    "        for cam_idx in range(graph.ncams_):\n",
    "            rvec = params[ptr:ptr+3]\n",
    "            tvec = params[ptr+3:ptr+6]\n",
    "            ptr += 6\n",
    "            proj = project(points_3d, rvec, tvec, f, cx, cy)\n",
    "            res.append((proj - obs[cam_idx]).ravel())\n",
    "        return np.concatenate(res)\n",
    "\n",
    "    # Run nonlinear least squares optimization\n",
    "    least_squares(residual, camera_params, verbose=1, ftol=1e-8, xtol=1e-8, method=\"lm\")\n",
    "\n",
    "    # In real implementations, the optimized parameters would update graph.extrinsics_mat_ and intr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bd15fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.optimize import least_squares\n",
    "from PIL import Image, ExifTags  # optional, for EXIF focal retrieval\n",
    "import math\n",
    "import copy\n",
    "\n",
    "# ---------- Helper utilities ----------\n",
    "\n",
    "def get_focal_from_exif(image_path):\n",
    "    \"\"\"Try to extract focal length in pixels from EXIF. Return None if unavailable.\"\"\"\n",
    "    try:\n",
    "        im = Image.open(image_path)\n",
    "        exif = im._getexif()\n",
    "        if not exif:\n",
    "            return None\n",
    "        # find focal length tag id\n",
    "        for tag, name in ExifTags.TAGS.items():\n",
    "            if name == 'FocalLength':\n",
    "                focal_tag = tag\n",
    "                break\n",
    "        if focal_tag not in exif:\n",
    "            return None\n",
    "        fl = exif[focal_tag]  # usually a tuple (num, den)\n",
    "        if isinstance(fl, tuple):\n",
    "            fl_value = float(fl[0]) / float(fl[1])\n",
    "        else:\n",
    "            fl_value = float(fl)\n",
    "        # If pixel size / sensor size unknown, this is focal in mm. We can't convert reliably\n",
    "        return fl_value\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def build_mat_from_params(f):\n",
    "    \"\"\"Return K given focal length f (float) and assumed principal point at image center set later.\"\"\"\n",
    "    return np.array([[f, 0.0, 0.0],\n",
    "                     [0.0, f, 0.0],\n",
    "                     [0.0, 0.0, 1.0]], dtype=float)\n",
    "\n",
    "def baseline_angle_from_extrinsics(M1, M2):\n",
    "    \"\"\"Compute angle between camera optical axes using extrinsic matrices: M = [R|t].\"\"\"\n",
    "    R1 = M1[:, :3]\n",
    "    R2 = M2[:, :3]\n",
    "    # camera optical axis is the third column of R^T (i.e., R[:,2])\n",
    "    z1 = R1[:, 2]\n",
    "    z2 = R2[:, 2]\n",
    "    # angle\n",
    "    cosang = np.clip(np.dot(z1, z2) / (np.linalg.norm(z1) * np.linalg.norm(z2)), -1.0, 1.0)\n",
    "    return math.degrees(math.acos(cosang))\n",
    "\n",
    "# ---------- Core pipeline functions ----------\n",
    "\n",
    "def estimate_fundamental_and_inliers(pair, keys, ransac_reproj_thresh=1.0, confidence=0.99):\n",
    "    \"\"\"\n",
    "    Build point correspondences from pair.matches_, estimate F using RANSAC,\n",
    "    return F (3x3) and inlier_mask (boolean array).\n",
    "    \"\"\"\n",
    "    ind1, ind2 = pair.cams_\n",
    "    if len(pair.matches_) < 8:\n",
    "        return None, None\n",
    "\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "    for m in pair.matches_:\n",
    "        kp1 = keys[ind1][m.ind_key_[0]].pt\n",
    "        kp2 = keys[ind2][m.ind_key_[1]].pt\n",
    "        pts1.append(kp1)\n",
    "        pts2.append(kp2)\n",
    "\n",
    "    pts1 = np.array(pts1, dtype=np.float32)\n",
    "    pts2 = np.array(pts2, dtype=np.float32)\n",
    "\n",
    "    # use RANSAC to estimate fundamental matrix\n",
    "    F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC, ransac_reproj_thresh, confidence)\n",
    "    if F is None or mask is None:\n",
    "        return None, None\n",
    "    mask = mask.ravel().astype(bool)\n",
    "    return F, mask\n",
    "\n",
    "def essential_from_F(F, K1, K2):\n",
    "    \"\"\"Compute E = K2^T * F * K1\"\"\"\n",
    "    return K2.T @ F @ K1\n",
    "\n",
    "def recover_pose_from_E(E, pts1, pts2, K1, K2):\n",
    "    \"\"\"Use cv2.recoverPose to obtain R, t and mask of inliers.\"\"\"\n",
    "    # OpenCV expects pts in shape Nx2 and type float\n",
    "    pts1 = np.array(pts1, dtype=np.float32)\n",
    "    pts2 = np.array(pts2, dtype=np.float32)\n",
    "    # normalize by K (recoverPose accepts K and pts in pixel coords)\n",
    "    retval, R, t, mask = cv2.recoverPose(E, pts1, pts2, K1)\n",
    "    mask = mask.ravel().astype(bool)\n",
    "    return R, t, mask\n",
    "\n",
    "def triangulate_pair(K1, M1, K2, M2, pts1, pts2):\n",
    "    \"\"\"\n",
    "    Linear triangulation via cv2.triangulatePoints.\n",
    "    M1, M2 are 3x4 extrinsic matrices.\n",
    "    pts1, pts2 Nx2 (float32)\n",
    "    Returns Nx3 array of 3D points.\n",
    "    \"\"\"\n",
    "    P1 = K1 @ M1\n",
    "    P2 = K2 @ M2\n",
    "    pts1_t = np.array(pts1, dtype=np.float64).T\n",
    "    pts2_t = np.array(pts2, dtype=np.float64).T\n",
    "    points4d = cv2.triangulatePoints(P1, P2, pts1_t, pts2_t)  # 4xN\n",
    "    points3d = (points4d[:3] / points4d[3]).T\n",
    "    return points3d\n",
    "\n",
    "def simple_bundle_adjust(graph, optimize_focal=False, optimize_intrinsics=False, max_nfev=200):\n",
    "    \"\"\"\n",
    "    Lightweight bundle adjustment that refines camera poses and optionally focal length.\n",
    "    This is a simplified version: assumes small graph (2 views) and that correspondences are aligned.\n",
    "    \"\"\"\n",
    "    # Flatten camera parameters (rvec, tvec) and optionally focal length\n",
    "    n_cams = graph.ncams_\n",
    "    n_points = len(graph.structure_points_)\n",
    "    if n_cams < 2 or n_points == 0:\n",
    "        return\n",
    "\n",
    "    # pack camera params\n",
    "    cam_params = []\n",
    "    for M in graph.extrinsics_mat_:\n",
    "        R = M[:, :3]\n",
    "        t = M[:, 3]\n",
    "        rvec, _ = cv2.Rodrigues(R)\n",
    "        cam_params.append(np.hstack((rvec.flatten(), t.flatten())))\n",
    "    cam_params = np.hstack(cam_params)  # length 6*n_cams\n",
    "\n",
    "    points3d = graph.structure_points_.copy().reshape(-1)  # 3*n_points\n",
    "\n",
    "    # intrinsics (we assume same K for all cams here for simplicity)\n",
    "    K0 = graph.intrinsics_mat_[0]\n",
    "    f0 = K0[0,0]\n",
    "    cx = K0[0,2]\n",
    "    cy = K0[1,2]\n",
    "\n",
    "    # build observed 2D array obs[cam_idx] = Nx2\n",
    "    obs = []\n",
    "    for cam_idx in range(n_cams):\n",
    "        cam_obs = []\n",
    "        for tr in graph.tracks_:\n",
    "            # track expected to contain per-camera 2D observation: track.obs[cam_idx] or approximated as pt1/pt2\n",
    "            if cam_idx == 0:\n",
    "                cam_obs.append(tr.pt1)\n",
    "            else:\n",
    "                cam_obs.append(tr.pt2)\n",
    "        obs.append(np.array(cam_obs, dtype=np.float64))\n",
    "    obs = np.array(obs)  # shape (n_cams, n_points, 2)\n",
    "\n",
    "    def project_point(p3, rvec, tvec, f):\n",
    "        pts, _ = cv2.projectPoints(p3[np.newaxis,:], rvec, tvec, np.array([[f, 0, cx],[0,f,cy],[0,0,1]]), None)\n",
    "        return pts.ravel()\n",
    "\n",
    "    def residual(x):\n",
    "        # x contains cam_params and points3d and maybe f\n",
    "        ptr = 0\n",
    "        camp = []\n",
    "        for _ in range(n_cams):\n",
    "            r = x[ptr:ptr+3]; t = x[ptr+3:ptr+6]; ptr += 6\n",
    "            camp.append((r, t))\n",
    "        pts = x[ptr:ptr+3*n_points].reshape((n_points, 3))\n",
    "        ptr += 3*n_points\n",
    "        if optimize_focal:\n",
    "            f = x[ptr]\n",
    "        else:\n",
    "            f = f0\n",
    "\n",
    "        res = []\n",
    "        for ci in range(n_cams):\n",
    "            rvec, tvec = camp[ci]\n",
    "            for pi in range(n_points):\n",
    "                proj = project_point(pts[pi], rvec, tvec, f)  # returns (x,y)\n",
    "                res.extend(proj - obs[ci, pi])\n",
    "        return np.array(res)\n",
    "\n",
    "    # initial x\n",
    "    x0 = np.hstack([cam_params, points3d])\n",
    "    if optimize_focal:\n",
    "        x0 = np.hstack([x0, f0])\n",
    "\n",
    "    result = least_squares(residual, x0, verbose=0, max_nfev=max_nfev, xtol=1e-8, ftol=1e-8, method='lm')\n",
    "    # Update graph from result (very minimal)\n",
    "    # Unpack updated camera params and points\n",
    "    x = result.x\n",
    "    ptr = 0\n",
    "    for idx in range(n_cams):\n",
    "        rvec = x[ptr:ptr+3]; tvec = x[ptr+3:ptr+6]; ptr += 6\n",
    "        R, _ = cv2.Rodrigues(rvec)\n",
    "        t = tvec.reshape(3,1)\n",
    "        graph.extrinsics_mat_[idx] = np.hstack((R, t))\n",
    "    pts = x[ptr:ptr+3*n_points].reshape((n_points, 3))\n",
    "    graph.structure_points_ = pts\n",
    "    ptr += 3*n_points\n",
    "    if optimize_focal and ptr < len(x):\n",
    "        f_opt = x[ptr]\n",
    "        # update intrinsics for all cameras\n",
    "        for i in range(len(graph.intrinsics_mat_)):\n",
    "            K = graph.intrinsics_mat_[i]\n",
    "            K[0,0] = K[1,1] = f_opt\n",
    "            graph.intrinsics_mat_[i] = K\n",
    "\n",
    "def verify_graph(graph, min_baseline_angle=1.0, max_reproj=5.0):\n",
    "    \"\"\"Check baseline angle and reprojection error to accept/reject the graph.\"\"\"\n",
    "    if graph.ncams_ < 2:\n",
    "        return False\n",
    "    # baseline angle\n",
    "    ang = baseline_angle_from_extrinsics(graph.extrinsics_mat_[0], graph.extrinsics_mat_[1])\n",
    "    err = reprojection_error(graph)\n",
    "    ok = (abs(ang) >= min_baseline_angle) and (err <= max_reproj)\n",
    "    return ok, ang, err\n",
    "\n",
    "# ---------- Main loop over pairs: converts pseudocode to python ----------\n",
    "\n",
    "def two_view_sfm_main(pairs, keys, images, global_odir=None,\n",
    "                      thresh_inlier_ratio=0.2, update_focal=False, update_intrinsic=False):\n",
    "    \"\"\"\n",
    "    Main loop:\n",
    "      For each pair in pairs:\n",
    "        - robustly estimate F/E\n",
    "        - estimate pose\n",
    "        - triangulate points\n",
    "        - bundle adjust\n",
    "        - verify checks\n",
    "        - construct Graph g from pair p and append to list if successful\n",
    "    Returns list of Graph objects built successfully.\n",
    "    \"\"\"\n",
    "    graphs = []\n",
    "\n",
    "    for p_idx, pair in enumerate(pairs):\n",
    "        print(\"*******************************\")\n",
    "        print(f\" 2-View SfM of image {pair.cams_[0]+1} and {pair.cams_[1]+1}\")\n",
    "        print(\"*******************************\")\n",
    "\n",
    "        # 1) Estimate fundamental matrix and inlier mask\n",
    "        F, inlier_mask = estimate_fundamental_and_inliers(pair, keys)\n",
    "        if F is None:\n",
    "            print(\"F estimation failed, skipping pair.\")\n",
    "            continue\n",
    "        inlier_ratio = np.sum(inlier_mask) / len(inlier_mask)\n",
    "        print(f\"ratio of matching inliers: {inlier_ratio:.3f}\")\n",
    "        if inlier_ratio < thresh_inlier_ratio:\n",
    "            print(\"Too few inliers, skip.\")\n",
    "            continue\n",
    "\n",
    "        # update matches to inliers only\n",
    "        pair.update_matches(inlier_mask)\n",
    "\n",
    "        # 2) intrinsics: try to get from pair or EXIF (we need width/height and focal)\n",
    "        # If pair.intrinsics_mat_ not set, use fallback focal and image size\n",
    "        w = images[pair.cams_[0]].shape[1]\n",
    "        h = images[pair.cams_[0]].shape[0]\n",
    "        # If you have EXIF path info, try to read focal in mm (optional)\n",
    "        # For now use the hard-coded focal from your earlier snippet if desired, else approximate\n",
    "        # Example fallback focal in pixels (you can tune)\n",
    "        fallback_f = 1520.4\n",
    "        pair.update_intrinsics(fallback_f, w, h)\n",
    "        K1 = pair.intrinsics_mat_[0]\n",
    "        K2 = pair.intrinsics_mat_[1]\n",
    "\n",
    "        # 3) Compute Essential matrix and recover pose\n",
    "        pair.E_ = essential_from_F(F, K1, K2)\n",
    "\n",
    "        # prepare pts for recoverPose (only inlier points)\n",
    "        ind1, ind2 = pair.cams_\n",
    "        pts1 = []\n",
    "        pts2 = []\n",
    "        for m in pair.matches_:\n",
    "            pts1.append(keys[ind1][m.ind_key_[0]].pt)\n",
    "            pts2.append(keys[ind2][m.ind_key_[1]].pt)\n",
    "\n",
    "        R, t, pose_mask = recover_pose_from_E(pair.E_, pts1, pts2, K1, K2)\n",
    "\n",
    "        # store extrinsics into pair (camera1 at origin)\n",
    "        M1 = np.hstack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93daf20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.optimize import least_squares\n",
    "import math\n",
    "import copy\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "# ---------------------\n",
    "# Utility helpers used below (if you already have these from previous code, use those)\n",
    "# ---------------------\n",
    "def project_point_with_P(P: np.ndarray, X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Project a 3D point X (3,) with 3x4 P, return 2D (x,y).\"\"\"\n",
    "    Xh = np.array([X[0], X[1], X[2], 1.0], dtype=float)\n",
    "    p = P @ Xh\n",
    "    return (p[:2] / p[2]).astype(float)\n",
    "\n",
    "def triangulate_point_multiview(Ps: List[np.ndarray], pts: List[Tuple[float, float]]) -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Triangulate a single 3D point from multiple views.\n",
    "    Ps: list of 3x4 projection matrices\n",
    "    pts: list of corresponding 2D points (x,y)\n",
    "    returns 3-vector or None if failure\n",
    "    \"\"\"\n",
    "    if len(Ps) < 2 or len(Ps) != len(pts):\n",
    "        return None\n",
    "    A_rows = []\n",
    "    for P, (x, y) in zip(Ps, pts):\n",
    "        # x * P[2,:] - P[0,:]\n",
    "        A_rows.append(x * P[2, :] - P[0, :])\n",
    "        A_rows.append(y * P[2, :] - P[1, :])\n",
    "    A = np.vstack(A_rows)  # (2n x 4)\n",
    "    # Solve by SVD\n",
    "    try:\n",
    "        _, _, Vt = np.linalg.svd(A)\n",
    "        Xh = Vt[-1, :]\n",
    "        if abs(Xh[3]) < 1e-12:\n",
    "            return None\n",
    "        X = Xh[:3] / Xh[3]\n",
    "        return X\n",
    "    except np.linalg.LinAlgError:\n",
    "        return None\n",
    "\n",
    "def compute_point_reprojection_error_for_track(X: np.ndarray, graph: \"Graph\", track, return_per_view=False):\n",
    "    \"\"\"\n",
    "    For a given track (with per-camera 2D observations stored as track.obs: dict cam_idx->(x,y) or attributes pt1/pt2 for two-view),\n",
    "    compute per-view residuals and mean.\n",
    "    \"\"\"\n",
    "    residuals = []\n",
    "    for cam_idx, P in enumerate(graph.extrinsics_mat_):\n",
    "        # Need K to form P_camera = K @ [R|t] or we can assume graph.intrinsics_mat_ holds Ks aligned to graph.ind_cam_\n",
    "        # We'll assume graph.intrinsics_mat_[cam_idx] corresponds to graph.extrinsics_mat_[cam_idx]\n",
    "        if hasattr(track, \"obs\") and cam_idx in track.obs:\n",
    "            K = graph.intrinsics_mat_[cam_idx]\n",
    "            M = graph.extrinsics_mat_[cam_idx]\n",
    "            Pcam = K @ M\n",
    "            proj = project_point_with_P(Pcam, X)\n",
    "            observed = np.array(track.obs[cam_idx], dtype=float)\n",
    "            residuals.append(np.linalg.norm(proj - observed))\n",
    "    if len(residuals) == 0:\n",
    "        return (np.inf if not return_per_view else ([], np.inf))\n",
    "    if return_per_view:\n",
    "        return residuals, float(np.mean(residuals))\n",
    "    return float(np.mean(residuals))\n",
    "\n",
    "def baseline_angle_for_track(track, graph: \"Graph\"):\n",
    "    \"\"\"\n",
    "    Compute maximum baseline angle between camera optical axes that observe this track.\n",
    "    track.obs is expected to contain camera indices -> 2D points.\n",
    "    Returns angle in degrees.\n",
    "    \"\"\"\n",
    "    cams = sorted(list(track.obs.keys()))\n",
    "    if len(cams) < 2:\n",
    "        return 0.0\n",
    "    axes = []\n",
    "    for ci in cams:\n",
    "        M = graph.extrinsics_mat_[ci]\n",
    "        R = M[:, :3]\n",
    "        z = R[:, 2]  # optical axis direction in world coords (camera forwards)\n",
    "        axes.append(z / np.linalg.norm(z))\n",
    "    # compute max angle between any pair\n",
    "    max_ang = 0.0\n",
    "    for i in range(len(axes)):\n",
    "        for j in range(i + 1, len(axes)):\n",
    "            dot = np.clip(np.dot(axes[i], axes[j]), -1.0, 1.0)\n",
    "            ang = math.degrees(math.acos(dot))\n",
    "            if ang > max_ang:\n",
    "                max_ang = ang\n",
    "    return max_ang\n",
    "\n",
    "# ---------------------\n",
    "# Core merge & refine pipeline\n",
    "# ---------------------\n",
    "\n",
    "def pick_best_graph_to_merge(global_graph: \"Graph\", graphs: List[\"Graph\"]) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Pick the index of the graph in 'graphs' that has the maximum number of common track ids with global_graph.\n",
    "    Assumes tracks have an 'id' attribute.\n",
    "    Returns index or None if none share tracks.\n",
    "    \"\"\"\n",
    "    global_ids = {t.id for t in global_graph.tracks_}\n",
    "    best_idx = None\n",
    "    best_common = 0\n",
    "    for idx, g in enumerate(graphs):\n",
    "        ids = {t.id for t in g.tracks_}\n",
    "        common = len(global_ids.intersection(ids))\n",
    "        if common > best_common:\n",
    "            best_common = common\n",
    "            best_idx = idx\n",
    "    return best_idx\n",
    "\n",
    "def merge_graph_into_global(global_graph: \"Graph\", g: \"Graph\") -> \"Graph\":\n",
    "    \"\"\"\n",
    "    Merge graph g into global_graph. This does:\n",
    "      - merges camera lists (appends new cams, tracks),\n",
    "      - merges intrinsics/extrinsics aligned with cameras,\n",
    "      - merges tracks by track.id (common tracks are unified; new tracks appended).\n",
    "    Returns updated global_graph (modified in place as well).\n",
    "    \"\"\"\n",
    "    # map from incoming camera id to index in global_graph\n",
    "    # We'll assume both graphs use camera identifiers in ind_cam_ which are unique (e.g. original image indices).\n",
    "    # If not, we use their ind_cam_ lists directly.\n",
    "    # Build mapping: g.ind_cam_ -> global index (append if new)\n",
    "    cam_map = {}\n",
    "    for i, camid in enumerate(g.ind_cam_):\n",
    "        if camid in global_graph.ind_cam_:\n",
    "            cam_map[i] = global_graph.ind_cam_.index(camid)\n",
    "        else:\n",
    "            # append camera to global graph\n",
    "            global_graph.ind_cam_.append(camid)\n",
    "            global_graph.intrinsics_mat_.append(g.intrinsics_mat_[i].copy())\n",
    "            global_graph.extrinsics_mat_.append(g.extrinsics_mat_[i].copy())\n",
    "            cam_map[i] = len(global_graph.ind_cam_) - 1\n",
    "            global_graph.ncams_ += 1\n",
    "\n",
    "    # Merge tracks by id\n",
    "    # Build quick lookup for global tracks\n",
    "    global_tracks_by_id = {t.id: t for t in global_graph.tracks_}\n",
    "\n",
    "    for tr in g.tracks_:\n",
    "        tid = tr.id\n",
    "        # ensure track.obs exists: obs: dict cam_idx -> (x,y). If not, create it from pt1/pt2 for two-view case.\n",
    "        if not hasattr(tr, \"obs\"):\n",
    "            tr.obs = {}\n",
    "            # guess two-view style pt1/pt2 aligned to g.ind_cam_\n",
    "            if hasattr(tr, \"pt1\") and hasattr(tr, \"pt2\") and len(g.ind_cam_) >= 2:\n",
    "                tr.obs[g.ind_cam_[0]] = tuple(np.array(tr.pt1).astype(float))\n",
    "                tr.obs[g.ind_cam_[1]] = tuple(np.array(tr.pt2).astype(float))\n",
    "\n",
    "        if tid in global_tracks_by_id:\n",
    "            # merge observations: add any observations from tr into existing global track\n",
    "            gtr = global_tracks_by_id[tid]\n",
    "            if not hasattr(gtr, \"obs\"):\n",
    "                gtr.obs = {}\n",
    "            for cam_local_idx, obs_xy in tr.obs.items():\n",
    "                # map cam_local_idx in g to global index via cam_map and then to the camera id\n",
    "                # But tr.obs keys are camera **ids** or local indices? We wrote obs keyed by camera id above.\n",
    "                # assume keys are camera ids (consistent with tr.id being global id).\n",
    "                camid = cam_local_idx\n",
    "                # find if camid is in global_graph.ind_cam_\n",
    "                if camid in global_graph.ind_cam_:\n",
    "                    gtr.obs[camid] = tuple(np.array(obs_xy, dtype=float))\n",
    "                else:\n",
    "                    # improbable, but if tr.obs keyed by local indices, map them\n",
    "                    # if cam_local_idx < len(g.ind_cam_): map using cam_map\n",
    "                    if isinstance(cam_local_idx, int) and cam_local_idx in cam_map:\n",
    "                        mapped_idx = cam_map[cam_local_idx]\n",
    "                        mapped_camid = global_graph.ind_cam_[mapped_idx]\n",
    "                        gtr.obs[mapped_camid] = tuple(np.array(obs_xy, dtype=float))\n",
    "                    else:\n",
    "                        # skip ambiguous observation\n",
    "                        continue\n",
    "        else:\n",
    "            # new track, remap its obs keys to global camera ids and append\n",
    "            new_tr = copy.deepcopy(tr)\n",
    "            if not hasattr(new_tr, \"obs\"):\n",
    "                new_tr.obs = {}\n",
    "                if hasattr(new_tr, \"pt1\") and hasattr(new_tr, \"pt2\") and len(g.ind_cam_) >= 2:\n",
    "                    new_tr.obs[g.ind_cam_[0]] = tuple(np.array(new_tr.pt1).astype(float))\n",
    "                    new_tr.obs[g.ind_cam_[1]] = tuple(np.array(new_tr.pt2).astype(float))\n",
    "            # remap keys if needed\n",
    "            remapped_obs = {}\n",
    "            for key, val in new_tr.obs.items():\n",
    "                if key in g.ind_cam_:\n",
    "                    local_idx = g.ind_cam_.index(key)\n",
    "                    mapped_global_idx = cam_map[local_idx]\n",
    "                    mapped_camid = global_graph.ind_cam_[mapped_global_idx]\n",
    "                    remapped_obs[mapped_camid] = tuple(np.array(val, dtype=float))\n",
    "                else:\n",
    "                    # if key is already a global cam id (likely), keep it\n",
    "                    remapped_obs[key] = tuple(np.array(val, dtype=float))\n",
    "            new_tr.obs = remapped_obs\n",
    "            global_graph.tracks_.append(new_tr)\n",
    "\n",
    "    # Done merging cameras and tracks\n",
    "    return global_graph\n",
    "\n",
    "def triangulate_all_tracks_in_graph(graph: \"Graph\", min_views=2):\n",
    "    \"\"\"\n",
    "    For every track in graph.tracks_, triangulate from all available views and set graph.structure_points_.\n",
    "    Only triangulates tracks observed in >= min_views.\n",
    "    \"\"\"\n",
    "    pts3d = []\n",
    "    valid_tracks = []\n",
    "    for tr in graph.tracks_:\n",
    "        if not hasattr(tr, \"obs\"):\n",
    "            continue\n",
    "        cams = sorted(list(tr.obs.keys()))\n",
    "        if len(cams) < min_views:\n",
    "            continue\n",
    "        Ps = []\n",
    "        pts = []\n",
    "        for camid in cams:\n",
    "            # get index of camid in graph.ind_cam_\n",
    "            if camid not in graph.ind_cam_:\n",
    "                continue\n",
    "            idx = graph.ind_cam_.index(camid)\n",
    "            K = graph.intrinsics_mat_[idx]\n",
    "            M = graph.extrinsics_mat_[idx]\n",
    "            Pcam = K @ M\n",
    "            Ps.append(Pcam)\n",
    "            pts.append(tuple(map(float, tr.obs[camid])))\n",
    "        if len(Ps) < min_views:\n",
    "            continue\n",
    "        X = triangulate_point_multiview(Ps, pts)\n",
    "        if X is not None and np.isfinite(X).all():\n",
    "            pts3d.append(X)\n",
    "            valid_tracks.append(tr)\n",
    "    graph.structure_points_ = np.array(pts3d, dtype=float) if len(pts3d) > 0 else np.zeros((0,3))\n",
    "    # Optionally keep only the valid_tracks in graph.tracks_\n",
    "    graph.tracks_ = valid_tracks\n",
    "\n",
    "def remove_outlier_tracks(graph: \"Graph\", min_baseline_angle_deg=1.0, max_reproj_error=5.0):\n",
    "    \"\"\"\n",
    "    Remove track entries (and associated 3D points) that fail baseline angle or reprojection error tests.\n",
    "    Assumes graph.structure_points_ aligns index-wise with graph.tracks_.\n",
    "    \"\"\"\n",
    "    if graph.structure_points_ is None or len(graph.structure_points_) == 0:\n",
    "        return\n",
    "    good_pts = []\n",
    "    good_tracks = []\n",
    "    for idx, tr in enumerate(graph.tracks_):\n",
    "        X = graph.structure_points_[idx]\n",
    "        base_ang = baseline_angle_for_track(tr, graph)\n",
    "        _, reproj_err = compute_point_reprojection_error_for_track(X, graph, tr, return_per_view=True)\n",
    "        mean_reproj = reproj_err\n",
    "        if base_ang >= min_baseline_angle_deg and mean_reproj <= max_reproj_error:\n",
    "            good_pts.append(X)\n",
    "            good_tracks.append(tr)\n",
    "    graph.structure_points_ = np.array(good_pts, dtype=float) if len(good_pts) > 0 else np.zeros((0,3))\n",
    "    graph.tracks_ = good_tracks\n",
    "\n",
    "# A minimal reprojection_error function for Graph using matched ordering:\n",
    "def reprojection_error_graph(graph: \"Graph\") -> float:\n",
    "    \"\"\"\n",
    "    compute mean reprojection error across all tracks and views present in graph.\n",
    "    \"\"\"\n",
    "    if graph.structure_points_ is None or len(graph.structure_points_) == 0:\n",
    "        return np.inf\n",
    "    total_err = 0.0\n",
    "    count = 0\n",
    "    for idx, tr in enumerate(graph.tracks_):\n",
    "        X = graph.structure_points_[idx]\n",
    "        for camid, obs in tr.obs.items():\n",
    "            if camid not in graph.ind_cam_:\n",
    "                continue\n",
    "            cam_idx = graph.ind_cam_.index(camid)\n",
    "            K = graph.intrinsics_mat_[cam_idx]\n",
    "            M = graph.extrinsics_mat_[cam_idx]\n",
    "            Pcam = K @ M\n",
    "            proj = project_point_with_P(Pcam, X)\n",
    "            total_err += np.linalg.norm(proj - np.array(obs))\n",
    "            count += 1\n",
    "    return (total_err / count) if count > 0 else np.inf\n",
    "\n",
    "# A stub/simple BA wrapper that calls simple_bundle_adjust you already have (adapts signatures)\n",
    "def run_bundle_adjustment_graph(graph: \"Graph\", optimize_focal=False, optimize_intrinsics=False):\n",
    "    \"\"\"\n",
    "    Wraps the previously defined simple_bundle_adjust function (which expects graph fields\n",
    "    similarly named). Here we assume graph.extrinsics_mat_ is a list of 3x4 matrices and\n",
    "    graph.intrinsics_mat_ a list of 3x3 Ks.\n",
    "    \"\"\"\n",
    "    # Reuse simple_bundle_adjust from earlier code. If you haven't defined it exactly,\n",
    "    # replace with a call to your own bundle adjustment implementation.\n",
    "    simple_bundle_adjust(graph, optimize_focal=optimize_focal, optimize_intrinsics=optimize_intrinsics)\n",
    "\n",
    "# ---------------------\n",
    "# Top-level merging loop\n",
    "# ---------------------\n",
    "\n",
    "def merge_graphs_into_global(graphs: List[\"Graph\"],\n",
    "                             global_graph: \"Graph\",\n",
    "                             min_common_tracks = 2,\n",
    "                             min_views_for_triangulation = 2,\n",
    "                             min_baseline_angle_deg = 1.0,\n",
    "                             max_reproj_error = 5.0,\n",
    "                             do_second_ba = True,\n",
    "                             update_focal=False,\n",
    "                             update_intrinsics=False):\n",
    "    \"\"\"\n",
    "    Merge graphs in 'graphs' into global_graph iteratively using your pseudocode:\n",
    "      - pick graph g with max common tracks\n",
    "      - merge\n",
    "      - triangulate\n",
    "      - BA\n",
    "      - remove track outliers by baseline angle and reprojection error\n",
    "      - BA\n",
    "    Returns final global_graph.\n",
    "    \"\"\"\n",
    "    remaining = graphs.copy()\n",
    "    while remaining:\n",
    "        best_idx = pick_best_graph_to_merge(global_graph, remaining)\n",
    "        if best_idx is None:\n",
    "            # pick any with at least min_common_tracks? or break\n",
    "            # If no graphs share tracks, we can optionally pick the next largest or break.\n",
    "            print(\"No remaining graph shares tracks with global_graph. Stopping merge.\")\n",
    "            break\n",
    "        g = remaining.pop(best_idx)\n",
    "        print(f\"Merging graph with cameras {g.ind_cam_} into global graph (global cams: {global_graph.ind_cam_})\")\n",
    "\n",
    "        # quick check: require at least min_common_tracks in common (adjust policy)\n",
    "        common_ids = set(t.id for t in global_graph.tracks_).intersection({t.id for t in g.tracks_})\n",
    "        if len(common_ids) < min_common_tracks:\n",
    "            print(f\"Graph has only {len(common_ids)} common tracks (< {min_common_tracks}), skipping.\")\n",
    "            continue\n",
    "\n",
    "        # 1) merge\n",
    "        merge_graph_into_global(global_graph, g)\n",
    "\n",
    "        # 2) triangulate tracks in merged global graph\n",
    "        triangulate_all_tracks_in_graph(global_graph, min_views=min_views_for_triangulation)\n",
    "\n",
    "        # 3) bundle adjustment (coarse)\n",
    "        print(\"Running bundle adjustment (coarse)...\")\n",
    "        run_bundle_adjustment_graph(global_graph, optimize_focal=update_focal, optimize_intrinsics=update_intrinsics)\n",
    "\n",
    "        # 4) remove outliers (baseline angle + reprojection)\n",
    "        print(\"Filtering outlier tracks...\")\n",
    "        remove_outlier_tracks(global_graph, min_baseline_angle_deg=min_baseline_angle_deg, max_reproj_error=max_reproj_error)\n",
    "\n",
    "        # 5) optional second BA\n",
    "        if do_second_ba:\n",
    "            print(\"Running bundle adjustment (final)...\")\n",
    "            run_bundle_adjustment_graph(global_graph, optimize_focal=update_focal, optimize_intrinsics=update_intrinsics)\n",
    "\n",
    "        # report\n",
    "        err = reprojection_error_graph(global_graph)\n",
    "        print(f\"Global graph now has {len(global_graph.tracks_)} tracks, reproj error: {err:.4f}\")\n",
    "\n",
    "    return global_graph\n",
    "\n",
    "# ---------------------\n",
    "# Example usage:\n",
    "# ---------------------\n",
    "# global_graph = Graph()  # initial global graph created from one seed pair/graph\n",
    "# final_global = merge_graphs_into_global(graphs, global_graph, min_common_tracks=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b345d7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=======================================\")\n",
    "print(\"   Multi-view Incremental SfM Process   \")\n",
    "print(\"=======================================\")\n",
    "\n",
    "# Initialize global graph with the first pair\n",
    "global_graph = Graph(graphs[0])\n",
    "\n",
    "for i in range(1, nimages - 1):\n",
    "    print(\"*******************************\")\n",
    "    print(f\" N-View SfM: merging graph 0-{i}\")\n",
    "    print(\"*******************************\")\n",
    "\n",
    "    # ------ merge graphs ------\n",
    "    Graph.merge_graph(global_graph, graphs[i])\n",
    "\n",
    "    # ------ N-view triangulation ------\n",
    "    triangulate_nonlinear(global_graph)\n",
    "    error = reprojection_error(global_graph)\n",
    "    print(f\"Reprojection error (before bundle adjustment): {error:.4f}\")\n",
    "\n",
    "    # ------ N-view bundle adjustment ------\n",
    "    print(\"------ start bundle adjustment ------\")\n",
    "    Open3DCVBundleAdjustment(global_graph, \"BUNDLE_PRINCIPAL_POINT\")\n",
    "    print(\"------ end bundle adjustment ------\")\n",
    "\n",
    "    # ------ Evaluate error ------\n",
    "    error = reprojection_error(global_graph)\n",
    "    print(f\"Reprojection error (after bundle adjustment): {error:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd04bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_Rt(Rt):\n",
    "    \"\"\"Inverse of a [3x4] pose matrix.\"\"\"\n",
    "    R = Rt[:, :3]\n",
    "    t = Rt[:, 3]\n",
    "    R_inv = R.T\n",
    "    t_inv = -R_inv @ t\n",
    "    Rt_inv = np.hstack((R_inv, t_inv.reshape(3, 1)))\n",
    "    return Rt_inv\n",
    "\n",
    "\n",
    "def concat_Rt(Rt1, Rt2):\n",
    "    \"\"\"Compose two extrinsic matrices: Rt_result = Rt1 * Rt2\"\"\"\n",
    "    R1, t1 = Rt1[:, :3], Rt1[:, 3]\n",
    "    R2, t2 = Rt2[:, :3], Rt2[:, 3]\n",
    "    R = R1 @ R2\n",
    "    t = R1 @ t2 + t1\n",
    "    return np.hstack((R, t.reshape(3, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00111db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bisect import bisect_left\n",
    "\n",
    "def merge_graph(graph1, graph2):\n",
    "    \"\"\"\n",
    "    Merge graph2 into graph1.\n",
    "    Equivalent to: void Graph::merge_graph(Graph &graph1, Graph &graph2)\n",
    "    \"\"\"\n",
    "\n",
    "    # ----- find overlapping cameras -----\n",
    "    cams_common = sorted(list(set(graph1.ind_cam_) & set(graph2.ind_cam_)))\n",
    "    cams_diff = sorted(list(set(graph2.ind_cam_) - set(graph1.ind_cam_)))\n",
    "\n",
    "    if not cams_common:\n",
    "        return  # nothing to merge if no shared cameras\n",
    "\n",
    "    # ----- merge camera intrinsics & extrinsics -----\n",
    "    ind_cam1 = graph1.index(cams_common[0])\n",
    "    ind_cam2 = graph2.index(cams_common[0])\n",
    "\n",
    "    Rt1 = graph1.extrinsics_mat_[ind_cam1]\n",
    "    Rt2 = graph2.extrinsics_mat_[ind_cam2]\n",
    "\n",
    "    # Rt21 = concat_Rt(inv_Rt(Rt1), Rt2)\n",
    "    Rt21 = concat_Rt(inv_Rt(Rt1), Rt2)\n",
    "\n",
    "    # transform structure points of graph2 into graph1 coordinate frame\n",
    "    for pt in graph2.structure_points_:\n",
    "        pt_h = np.append(pt.coords(), 1.0)\n",
    "        pt.coords_ = (Rt21 @ pt_h)[:3]\n",
    "\n",
    "    Rt21t = inv_Rt(Rt21)\n",
    "\n",
    "    # append non-overlapping cameras\n",
    "    for cam_id in cams_diff:\n",
    "        graph1.ind_cam_.append(cam_id)\n",
    "        graph1.intrinsics_mat_.append(graph2.intrinsics_mat_[graph2.index(cam_id)])\n",
    "        Rt2_rel = concat_Rt(graph2.extrinsics_mat_[graph2.index(cam_id)], Rt21t)\n",
    "        graph1.extrinsics_mat_.append(Rt2_rel)\n",
    "\n",
    "    # sort cameras (keep consistent ordering)\n",
    "    order = np.argsort(graph1.ind_cam_)\n",
    "    graph1.ind_cam_ = [graph1.ind_cam_[i] for i in order]\n",
    "    graph1.intrinsics_mat_ = [graph1.intrinsics_mat_[i] for i in order]\n",
    "    graph1.extrinsics_mat_ = [graph1.extrinsics_mat_[i] for i in order]\n",
    "    graph1.ncams_ = len(graph1.ind_cam_)\n",
    "\n",
    "    # ----- merge feature tracks -----\n",
    "    ntracks = len(graph1.tracks_)\n",
    "    for track2, struct_pt in zip(graph2.tracks_, graph2.structure_points_):\n",
    "        is_connected = False\n",
    "        for i in range(ntracks):\n",
    "            track1 = graph1.tracks_[i]\n",
    "            feats_common = Track.find_overlapping_keypoints(track1, track2)\n",
    "            if feats_common:\n",
    "                Graph.merge_tracks(track1, track2, feats_common)\n",
    "                is_connected = True\n",
    "                break\n",
    "        if not is_connected:\n",
    "            graph1.add_track(track2)\n",
    "            graph1.add_struct_pt(struct_pt)\n",
    "\n",
    "    # new features from non-overlapping cameras skipped for now\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
